{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3b) SVD Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnH9yrODGtGU"
      },
      "source": [
        "# Singular Value Decomposition (SVD) - Example\n",
        "\n",
        "Reducing the number of input variables for a predictive model is referred to as dimensionality reduction. Fewer input variables can result in a simpler predictive model that may have better performance when making predictions on new data. Perhaps the more popular technique for dimensionality reduction in machine learning is Singular Value Decomposition, or SVD for short. This is a technique that comes from the field of linear algebra and can be used as a data preparation technique to create a projection of a sparse dataset prior to fitting a model.\n",
        "\n",
        "Sparse data refers to rows of data where many of the values are zero. This is often the case in some problem domains like recommender systems where a user has a rating for very few movies or songs in the database and zero ratings for all other cases. Another common example is a bag of words model of a text document, where the document has a count or frequency for some words and most words have a 0 value.\n",
        "\n",
        "If your data is represented using rows and columns, such as in a spreadsheet, then the input variables are the columns that are fed as input to a model to predict the target variable. Input variables are also called features. We can consider the columns of data representing dimensions on an n-dimensional feature space and the rows of data as points in that space. This is a useful geometric interpretation of a dataset. Having a large number of dimensions in the feature space can mean that the volume of that space is very large, and in turn, the points that we have in that space (rows of data) often represent a small and non-representative sample. This can dramatically impact the performance of machine learning algorithms fit on data with many input features, generally referred to as the “curse of dimensionality.”\n",
        "\n",
        "A popular approach to dimensionality reduction is to use techniques from the field of linear algebra. This is often called “feature projection” and the algorithms used are referred to as “projection methods.” Projection methods seek to reduce the number of dimensions in the feature space whilst also preserving the most important structure or relationships between the variables observed in the data.\n",
        "\n",
        "In essence, the original features no longer exist and new features are constructed from the available data that are not directly comparable to the original data, e.g. don’t have column names. Any new data that is fed to the model in the future when making predictions, such as test datasets and new datasets, must also be projected using the same technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGDh1mWDIUKz"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTaV_u-xGa55"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3eHmPcxIehC"
      },
      "source": [
        "## Load data\n",
        "\n",
        "SVD is typically used on sparse data. This includes data for a recommender system or a bag of words model for text. If the data is dense, then it is better to use the PCA method. Nevertheless, for simplicity, we will demonstrate SVD on dense data in this section. You can easily adapt it for your own sparse dataset.\n",
        "\n",
        "First, we can use the make_classification() function to create a synthetic binary classification problem with 1,000 examples and 20 input features, 15 inputs of which are meaningful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUmgataMIYxt"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP_f25tpIpNW",
        "outputId": "d1300f5e-5d0d-419c-9013-b135407ee0c0"
      },
      "source": [
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH-Af42BIxts"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZtdZl-KIpfm"
      },
      "source": [
        "# define the model\n",
        "model = LogisticRegression()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9K1BAIHI09X"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcVOYQY2I3q1",
        "outputId": "5679a3ca-91a9-4cbe-81cd-10b540120e51"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.865 (0.027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9bzWPHDI6UL"
      },
      "source": [
        "## Model with SVD\n",
        "\n",
        "We will use a Pipeline where the first step performs the SVD transform and selects the 10 most important dimensions or components, then fits a logistic regression model on these features. We don’t need to normalize the variables on this dataset, as all variables have the same scale by design.\n",
        "\n",
        "The pipeline will be evaluated using repeated stratified cross-validation with three repeats and 10 folds per repeat. Performance is presented as the mean classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO87X8wVI5L2"
      },
      "source": [
        "# define the pipeline\n",
        "steps = [('svd', TruncatedSVD(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swYTyNleJM4i"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsq7i8g6JTCS",
        "outputId": "adbb492e-4cd5-4838-91a2-fad35c32217b"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.814 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJKMx1yMJbKj"
      },
      "source": [
        "How do we know that reducing 20 dimensions of input down to 10 is good or the best we can do?\n",
        "\n",
        "We don’t; 10 was an arbitrary choice.\n",
        "\n",
        "A better approach is to evaluate the same transform and model with different numbers of input features and choose the number of features (amount of dimensionality reduction) that results in the best average performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCYAJlrnJUUx"
      },
      "source": [
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
        "\treturn X, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1bhHZeDJe1D"
      },
      "source": [
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in range(1,20):\n",
        "\t\tsteps = [('svd', TruncatedSVD(n_components=i)), ('m', LogisticRegression())]\n",
        "\t\tmodels[str(i)] = Pipeline(steps=steps)\n",
        "\treturn models"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTxCfPhmJhmE"
      },
      "source": [
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvD3-d5hJn97"
      },
      "source": [
        "# define dataset\n",
        "X, y = get_dataset()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgBcVAHJrYg"
      },
      "source": [
        "# get the models to evaluate\n",
        "models = get_models()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO9fQ37nJtfg",
        "outputId": "8f378cbb-628c-489c-ad4e-ae7bad3c1030"
      },
      "source": [
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1 0.542 (0.046)\n",
            ">2 0.626 (0.050)\n",
            ">3 0.719 (0.053)\n",
            ">4 0.722 (0.052)\n",
            ">5 0.721 (0.054)\n",
            ">6 0.729 (0.045)\n",
            ">7 0.802 (0.034)\n",
            ">8 0.800 (0.040)\n",
            ">9 0.814 (0.037)\n",
            ">10 0.814 (0.034)\n",
            ">11 0.817 (0.037)\n",
            ">12 0.820 (0.038)\n",
            ">13 0.820 (0.036)\n",
            ">14 0.825 (0.036)\n",
            ">15 0.865 (0.027)\n",
            ">16 0.865 (0.027)\n",
            ">17 0.865 (0.027)\n",
            ">18 0.865 (0.027)\n",
            ">19 0.865 (0.027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "BnZRNzNFJv4Z",
        "outputId": "8a4062cd-b02f-4ec9-deaa-468f195ad9a6"
      },
      "source": [
        "# plot model performance for comparison\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.boxplot(results, labels=names, showmeans=True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"# principal components\", fontsize=12)\n",
        "plt.ylabel(\"Model Mean Accuracy\", fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4jV6S2NJ3aT"
      },
      "source": [
        "We can see a general trend of increased performance as the number of dimensions is increased. On this dataset, the results suggest a trade-off in the number of dimensions vs. the classification accuracy of the model. \n",
        "\n",
        "Interestingly, we don’t see any improvement beyond 15 components. This matches our definition of the problem where only the first 15 components contain information about the class and the remaining five are redundant.\n",
        "\n",
        "A box and whisker plot is created for the distribution of accuracy scores for each configured number of dimensions. We can see the trend of increasing classification accuracy with the number of components, with a limit at 15.\n",
        "\n",
        "We may choose to use an SVD transform and logistic regression model combination as our final model. This involves fitting the Pipeline on all available data and using the pipeline to make predictions on new data. Importantly, the same transform must be performed on this new data, which is handled automatically via the Pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXlWgmAhJzaY",
        "outputId": "61dfc11e-de22-43e7-ad7b-bd5cb7536f6d"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaFri8lDKirV"
      },
      "source": [
        "# define the model\n",
        "steps = [('svd', TruncatedSVD(n_components=15)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-GliAv7Kk7s",
        "outputId": "a07bedf2-5c44-4d71-bde1-b55dd2ce9cb0"
      },
      "source": [
        "# fit the model on the whole dataset\n",
        "model.fit(X, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('svd',\n",
              "                 TruncatedSVD(algorithm='randomized', n_components=15, n_iter=5,\n",
              "                              random_state=None, tol=0.0)),\n",
              "                ('m',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH1fNEa4Km9U",
        "outputId": "9c0deb4d-ae49-414c-db47-3a004d50fa21"
      },
      "source": [
        "# make a single prediction\n",
        "row = [[0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]]\n",
        "yhat = model.predict(row)\n",
        "print('Predicted Class: %d' % yhat[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyByVl1BKuJS"
      },
      "source": [
        "Running the example fits the Pipeline on all available data and makes a prediction on new data.\n",
        "\n",
        "Here, the transform uses the 15 most important components from the SVD transform, as we found from testing above.\n",
        "\n",
        "A new row of data with 20 columns is provided and is automatically transformed to 15 components and fed to the logistic regression model in order to predict the class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZSaLAiKpfG"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}