{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1) Isomap Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd55VmXkVe28"
      },
      "source": [
        "# Manifold Learning: Isomap Embedding\n",
        "\n",
        "Isomap Embedding, or Isomap, creates an embedding of the dataset and attempts to preserve the relationships in the dataset. The scikit-learn library provides the Isomap class implementation of Isomap Embedding that can be used as a dimensionality reduction data transform. The “n_components” argument can be set to configure the number of desired dimensions in the output of the transform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A7XBvQcV3Ji"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p6ntIHzNVAN"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrkdCTlgV8J3"
      },
      "source": [
        "## Load data\n",
        "\n",
        "We will use the make_classification() function to create a test binary classification dataset. The dataset will have 1,000 examples with 20 input features, 10 of which are informative and 10 of which are redundant. This provides an opportunity for each technique to identify and remove redundant input features. The fixed random seed for the pseudorandom number generator ensures we generate the same synthetic dataset each time the code runs.\n",
        "\n",
        "It is a binary classification task and we will evaluate a LogisticRegression model after each dimensionality reduction transform. The model will be evaluated using the gold standard of repeated stratified 10-fold cross-validation. The mean and standard deviation classification accuracy across all folds and repeats will be reported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyenXi_lV7Sp"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG91qqtHWAZ4",
        "outputId": "93bb2752-b5cd-4b59-d538-aea3c262874e"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-3JxhxXWEFW"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBgoHAKbWCNa"
      },
      "source": [
        "# define the model\n",
        "model = LogisticRegression()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIBmfBMJWJYk"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn8b-gqEWLGS",
        "outputId": "10463448-b68f-406b-831d-14cf8ea4e5d0"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w287-UFdWX4F"
      },
      "source": [
        "##  Model with Isomap Embedding\n",
        "\n",
        "We will use a Pipeline to combine the data transform and model into an atomic unit that can be evaluated using the cross-validation procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3msqSVOpWPk7"
      },
      "source": [
        "# define the pipeline\n",
        "steps = [('iso', Isomap(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK212oKNWhWt"
      },
      "source": [
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkReSGUHWjLe",
        "outputId": "e2d440da-1e61-46a5-828a-6a862d79e14d"
      },
      "source": [
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.888 (0.029)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b6AyjVSWosS"
      },
      "source": [
        "In this case, we can see a lift in performance with the Isomap data transform as compared to the baseline fit on the raw data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uazKCv41Wk4G"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}